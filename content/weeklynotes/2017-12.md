---
title:        Week 12 2017 - Docker Donates Containerd; Google's JPEG Compression 
slug:         week-12-2017
blog:         ig.nore.me  
author:       Arjen Schwarz  
Date:              2017-03-20T21:17:49+11:00  
categories:   ["Weekly Notes"]
Description:  "Docker donates containerd and Google comes with a new image compression technique."
---

Docker donates containerd and Google comes with a new image compression technique. Another short one this week, mainly because I've been so busy at work I barely get a chance to follow the news. This should change soon though, and maybe news will pick up then as well.

As a side note, last week I lamented how I didn't pay enough attention to Google Cloud. Coincidentally a couple days after posting that I learned that next week they have a conference here in Melbourne that I will be attending. If anything useful comes out of that I might just do a write up of it.

# Docker donates containerd

In my last note of 2016, I mentioned that Docker [spun out containerd](https://ig.nore.me/weekly-notes/week-52-2016/) into its own project. Now they're following up on the next step in this process by [offering it to the Cloud Native Computing Foundation](https://blog.docker.com/2017/03/docker-donates-containerd-to-cncf/). 

If this gets accepted, and while bureaucracy might take its time I can't see why not, that would ensure the core basis of containers is a standard governed by an independent party. The obvious benefit here is for compatibility between different projects, whether Docker or otherwise. If everyone uses the same basic container structure under the hood that means less chance of it being owned by a single company.

I already wrote a fair bit about this in last year's article, so I'm not going to repeat that here. Suffice to say that I'm happy to see this progressing.

# Google's JPEG compression

Google has been trying to introduce better and smaller image formats for a while now. The benefits in general are obvious, smaller images mean less traffic, and for a company like Google that handles large amounts of data any small saving immediately scales.

Their main attempt at this has been with the [WebP format](https://developers.google.com/speed/webp/), a completely new image format. Adoption of this has been slow though, not in the least due to it only being supported in Chrome and Opera[^1]. After all, if only a part of your visitors can see the image format it's easier to just have a single image that everyone can see.

This time however, Google open sourced a new [compression technique for JPEG](https://arstechnica.co.uk/information-technology/2017/03/google-jpeg-guetzli-encoder-file-size/). It looks like it might be useful and this time it's a method that works in every browser without much drawbacks, other than a slightly slower compression. Most interesting though is that not only does it make the images smaller, it also makes them look better. 

Google is quiet on how they managed this, but knowing them it likely involves machine learning. And as it happens, they have a [sizable database of photos](https://www.google.com/photos/about/) people uploaded with the expectation that they'd be compressed. That sounds like a perfect set of training data to me, but of course I could be completely wrong. It just makes sense to me that they will have tested the algorithm on all of these photos as a way to ensure it works well. 

[^1]:	This comes from their website, I honestly thought that Firefox might support it but apparently not.
